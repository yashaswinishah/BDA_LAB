<pre><font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hadoop
Usage: hadoop [--config confdir] COMMAND
       where COMMAND is one of:
  fs                   run a generic filesystem user client
  version              print the version
  jar &lt;jar&gt;            run a jar file
  checknative [-a|-h]  check native hadoop and compression libraries availability
  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively
  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive
  classpath            prints the class path needed to get the
  credential           interact with credential providers
                       Hadoop jar and the required libraries
  daemonlog            get/set the log level for each daemon
  trace                view and modify Hadoop tracing settings
 or
  CLASSNAME            run the class named CLASSNAME

Most commands print help when invoked w/o parameters.
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ su hdfs
su: user hdfs does not exist
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ su
Password: 
su: Authentication failure
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ start-all.sh
This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
Starting namenodes on [localhost]
hduser@localhost&apos;s password: 
localhost: starting namenode, logging to /usr/local/hadoop/logs/hadoop-hduser-namenode-bmsce-Precision-T1700.out
hduser@localhost&apos;s password: 
localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-hduser-datanode-bmsce-Precision-T1700.out
Starting secondary namenodes [0.0.0.0]
hduser@0.0.0.0&apos;s password: 
0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-hduser-secondarynamenode-bmsce-Precision-T1700.out
starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop/logs/yarn-hduser-resourcemanager-bmsce-Precision-T1700.out
hduser@localhost&apos;s password: 
localhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-hduser-nodemanager-bmsce-Precision-T1700.out
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ jps
6832 SecondaryNameNode
7447 Jps
6619 DataNode
7324 NodeManager
6446 NameNode
6991 ResourceManager
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hdfs dfs -mkdir /yashaswini
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hdfs dfs copy -FromLocal /home/hduser/Desktop/yashaswini/text.txt
copy: Unknown command
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hdfs dfs -FromLocal /home/hduser/Desktop/yashaswini/text.txt
-FromLocal: Unknown command
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hdfs dfs -put /home/hduser/Desktop/text.txt /yashaswini/text.txt
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hadoop jar /home/hduser/Desktop/TopN216.jar TopN /yashaswini/text.txt
Usage: TopN &lt;in&gt; &lt;out&gt;
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hadoop jar /home/hduser/Desktop/TopN216.jar TopN /yashaswini/text.txt out216
22/06/25 10:32:28 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
22/06/25 10:32:28 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
22/06/25 10:32:28 INFO input.FileInputFormat: Total input paths to process : 1
22/06/25 10:32:28 INFO mapreduce.JobSubmitter: number of splits:1
22/06/25 10:32:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local955723247_0001
22/06/25 10:32:28 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
22/06/25 10:32:28 INFO mapreduce.Job: Running job: job_local955723247_0001
22/06/25 10:32:28 INFO mapred.LocalJobRunner: OutputCommitter set in config null
22/06/25 10:32:28 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
22/06/25 10:32:28 INFO mapred.LocalJobRunner: Waiting for map tasks
22/06/25 10:32:28 INFO mapred.LocalJobRunner: Starting task: attempt_local955723247_0001_m_000000_0
22/06/25 10:32:28 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
22/06/25 10:32:28 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/yashaswini/text.txt:0+65
22/06/25 10:32:28 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
22/06/25 10:32:28 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
22/06/25 10:32:28 INFO mapred.MapTask: soft limit at 83886080
22/06/25 10:32:28 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
22/06/25 10:32:28 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
22/06/25 10:32:28 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
22/06/25 10:32:28 INFO input.LineRecordReader: Found UTF-8 BOM and skipped it
22/06/25 10:32:28 INFO mapred.LocalJobRunner: 
22/06/25 10:32:28 INFO mapred.MapTask: Starting flush of map output
22/06/25 10:32:28 INFO mapred.MapTask: Spilling map output
22/06/25 10:32:28 INFO mapred.MapTask: bufstart = 0; bufend = 110; bufvoid = 104857600
22/06/25 10:32:28 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
22/06/25 10:32:29 INFO mapred.MapTask: Finished spill 0
22/06/25 10:32:29 INFO mapred.Task: Task:attempt_local955723247_0001_m_000000_0 is done. And is in the process of committing
22/06/25 10:32:29 INFO mapred.LocalJobRunner: map
22/06/25 10:32:29 INFO mapred.Task: Task &apos;attempt_local955723247_0001_m_000000_0&apos; done.
22/06/25 10:32:29 INFO mapred.LocalJobRunner: Finishing task: attempt_local955723247_0001_m_000000_0
22/06/25 10:32:29 INFO mapred.LocalJobRunner: map task executor complete.
22/06/25 10:32:29 INFO mapred.LocalJobRunner: Waiting for reduce tasks
22/06/25 10:32:29 INFO mapred.LocalJobRunner: Starting task: attempt_local955723247_0001_r_000000_0
22/06/25 10:32:29 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
22/06/25 10:32:29 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4928b3df
22/06/25 10:32:29 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
22/06/25 10:32:29 INFO reduce.EventFetcher: attempt_local955723247_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
22/06/25 10:32:29 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local955723247_0001_m_000000_0 decomp: 136 len: 140 to MEMORY
22/06/25 10:32:29 INFO reduce.InMemoryMapOutput: Read 136 bytes from map-output for attempt_local955723247_0001_m_000000_0
22/06/25 10:32:29 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 136, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;136
22/06/25 10:32:29 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
22/06/25 10:32:29 INFO mapred.LocalJobRunner: 1 / 1 copied.
22/06/25 10:32:29 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
22/06/25 10:32:29 INFO mapred.Merger: Merging 1 sorted segments
22/06/25 10:32:29 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 132 bytes
22/06/25 10:32:29 INFO reduce.MergeManagerImpl: Merged 1 segments, 136 bytes to disk to satisfy reduce memory limit
22/06/25 10:32:29 INFO reduce.MergeManagerImpl: Merging 1 files, 140 bytes from disk
22/06/25 10:32:29 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
22/06/25 10:32:29 INFO mapred.Merger: Merging 1 sorted segments
22/06/25 10:32:29 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 132 bytes
22/06/25 10:32:29 INFO mapred.LocalJobRunner: 1 / 1 copied.
22/06/25 10:32:29 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
22/06/25 10:32:29 INFO mapred.Task: Task:attempt_local955723247_0001_r_000000_0 is done. And is in the process of committing
22/06/25 10:32:29 INFO mapred.LocalJobRunner: 1 / 1 copied.
22/06/25 10:32:29 INFO mapred.Task: Task attempt_local955723247_0001_r_000000_0 is allowed to commit now
22/06/25 10:32:29 INFO output.FileOutputCommitter: Saved output of task &apos;attempt_local955723247_0001_r_000000_0&apos; to hdfs://localhost:54310/user/hduser/out216/_temporary/0/task_local955723247_0001_r_000000
22/06/25 10:32:29 INFO mapred.LocalJobRunner: reduce &gt; reduce
22/06/25 10:32:29 INFO mapred.Task: Task &apos;attempt_local955723247_0001_r_000000_0&apos; done.
22/06/25 10:32:29 INFO mapred.LocalJobRunner: Finishing task: attempt_local955723247_0001_r_000000_0
22/06/25 10:32:29 INFO mapred.LocalJobRunner: reduce task executor complete.
22/06/25 10:32:29 INFO mapreduce.Job: Job job_local955723247_0001 running in uber mode : false
22/06/25 10:32:29 INFO mapreduce.Job:  map 100% reduce 100%
22/06/25 10:32:29 INFO mapreduce.Job: Job job_local955723247_0001 completed successfully
22/06/25 10:32:29 INFO mapreduce.Job: Counters: 38
	File System Counters
		FILE: Number of bytes read=17618
		FILE: Number of bytes written=516062
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=130
		HDFS: Number of bytes written=86
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=1
		Map output records=12
		Map output bytes=110
		Map output materialized bytes=140
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=140
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=41
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=576192512
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=65
	File Output Format Counters 
		Bytes Written=86
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hadoop fs -ls /out216/
ls: `/out216/&apos;: No such file or directory
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hadoop jar /home/hduser/Desktop/TopN216.jar TopN /yashaswini/text.txt /out100
22/06/25 10:35:29 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
22/06/25 10:35:29 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
22/06/25 10:35:30 INFO input.FileInputFormat: Total input paths to process : 1
22/06/25 10:35:30 INFO mapreduce.JobSubmitter: number of splits:1
22/06/25 10:35:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1725021352_0001
22/06/25 10:35:30 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
22/06/25 10:35:30 INFO mapreduce.Job: Running job: job_local1725021352_0001
22/06/25 10:35:30 INFO mapred.LocalJobRunner: OutputCommitter set in config null
22/06/25 10:35:30 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
22/06/25 10:35:30 INFO mapred.LocalJobRunner: Waiting for map tasks
22/06/25 10:35:30 INFO mapred.LocalJobRunner: Starting task: attempt_local1725021352_0001_m_000000_0
22/06/25 10:35:30 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
22/06/25 10:35:30 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/yashaswini/text.txt:0+65
22/06/25 10:35:30 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
22/06/25 10:35:30 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
22/06/25 10:35:30 INFO mapred.MapTask: soft limit at 83886080
22/06/25 10:35:30 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
22/06/25 10:35:30 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
22/06/25 10:35:30 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
22/06/25 10:35:30 INFO input.LineRecordReader: Found UTF-8 BOM and skipped it
22/06/25 10:35:30 INFO mapred.LocalJobRunner: 
22/06/25 10:35:30 INFO mapred.MapTask: Starting flush of map output
22/06/25 10:35:30 INFO mapred.MapTask: Spilling map output
22/06/25 10:35:30 INFO mapred.MapTask: bufstart = 0; bufend = 110; bufvoid = 104857600
22/06/25 10:35:30 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
22/06/25 10:35:30 INFO mapred.MapTask: Finished spill 0
22/06/25 10:35:30 INFO mapred.Task: Task:attempt_local1725021352_0001_m_000000_0 is done. And is in the process of committing
22/06/25 10:35:30 INFO mapred.LocalJobRunner: map
22/06/25 10:35:30 INFO mapred.Task: Task &apos;attempt_local1725021352_0001_m_000000_0&apos; done.
22/06/25 10:35:30 INFO mapred.LocalJobRunner: Finishing task: attempt_local1725021352_0001_m_000000_0
22/06/25 10:35:30 INFO mapred.LocalJobRunner: map task executor complete.
22/06/25 10:35:30 INFO mapred.LocalJobRunner: Waiting for reduce tasks
22/06/25 10:35:30 INFO mapred.LocalJobRunner: Starting task: attempt_local1725021352_0001_r_000000_0
22/06/25 10:35:30 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
22/06/25 10:35:30 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2433c3ad
22/06/25 10:35:30 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
22/06/25 10:35:30 INFO reduce.EventFetcher: attempt_local1725021352_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
22/06/25 10:35:30 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1725021352_0001_m_000000_0 decomp: 136 len: 140 to MEMORY
22/06/25 10:35:30 INFO reduce.InMemoryMapOutput: Read 136 bytes from map-output for attempt_local1725021352_0001_m_000000_0
22/06/25 10:35:30 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 136, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;136
22/06/25 10:35:30 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
22/06/25 10:35:30 INFO mapred.LocalJobRunner: 1 / 1 copied.
22/06/25 10:35:30 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
22/06/25 10:35:30 INFO mapred.Merger: Merging 1 sorted segments
22/06/25 10:35:30 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 132 bytes
22/06/25 10:35:30 INFO reduce.MergeManagerImpl: Merged 1 segments, 136 bytes to disk to satisfy reduce memory limit
22/06/25 10:35:30 INFO reduce.MergeManagerImpl: Merging 1 files, 140 bytes from disk
22/06/25 10:35:30 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
22/06/25 10:35:30 INFO mapred.Merger: Merging 1 sorted segments
22/06/25 10:35:30 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 132 bytes
22/06/25 10:35:30 INFO mapred.LocalJobRunner: 1 / 1 copied.
22/06/25 10:35:30 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
22/06/25 10:35:30 INFO mapred.Task: Task:attempt_local1725021352_0001_r_000000_0 is done. And is in the process of committing
22/06/25 10:35:30 INFO mapred.LocalJobRunner: 1 / 1 copied.
22/06/25 10:35:30 INFO mapred.Task: Task attempt_local1725021352_0001_r_000000_0 is allowed to commit now
22/06/25 10:35:30 INFO output.FileOutputCommitter: Saved output of task &apos;attempt_local1725021352_0001_r_000000_0&apos; to hdfs://localhost:54310/out100/_temporary/0/task_local1725021352_0001_r_000000
22/06/25 10:35:30 INFO mapred.LocalJobRunner: reduce &gt; reduce
22/06/25 10:35:30 INFO mapred.Task: Task &apos;attempt_local1725021352_0001_r_000000_0&apos; done.
22/06/25 10:35:30 INFO mapred.LocalJobRunner: Finishing task: attempt_local1725021352_0001_r_000000_0
22/06/25 10:35:30 INFO mapred.LocalJobRunner: reduce task executor complete.
22/06/25 10:35:31 INFO mapreduce.Job: Job job_local1725021352_0001 running in uber mode : false
22/06/25 10:35:31 INFO mapreduce.Job:  map 100% reduce 100%
22/06/25 10:35:31 INFO mapreduce.Job: Job job_local1725021352_0001 completed successfully
22/06/25 10:35:31 INFO mapreduce.Job: Counters: 38
	File System Counters
		FILE: Number of bytes read=17618
		FILE: Number of bytes written=518726
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=130
		HDFS: Number of bytes written=86
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=1
		Map output records=12
		Map output bytes=110
		Map output materialized bytes=140
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=140
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=40
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=578289664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=65
	File Output Format Counters 
		Bytes Written=86
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hadoop fs -ls /out100
Found 2 items
-rw-r--r--   1 hduser supergroup          0 2022-06-25 10:35 /out100/_SUCCESS
-rw-r--r--   1 hduser supergroup         86 2022-06-25 10:35 /out100/part-r-00000
<font color="#4E9A06"><b>hduser@bmsce-Precision-T1700</b></font>:<font color="#3465A4"><b>~</b></font>$ hadoop fs -cat /out100/part-r-00000
a	1
on	1
the	1
cat	1
bbbbbb	1
cccccc	1
table	1
aaaaa	1
dddddd	1
is	1
there	1
eeeeee	1
</pre>
